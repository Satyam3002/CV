{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import random\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset_path = \"/kaggle/input/thermal-dataset\"\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, txt_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_file (string): Path to the .txt file containing image paths and label IDs.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        with open(txt_file, 'r') as file:\n",
    "            for line in file:\n",
    "                image_path , label = line.strip().split(\"|\")\n",
    "                image_path = image_path.replace(\"/home/infinity/Documents/PlantVillage-Dataset/raw\" , \"/content/raw/raw\")\n",
    "                self.data.append((image_path, int(label)))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "dataset = ImageDataset(\"/content/drive/MyDrive/train.txt\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageDataset(\"/content/drive/MyDrive/test.txt\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "print(f\"Training samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = models.googlenet(weights=models.GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "num_classes = 38\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "num_epochs = 1\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), \"googlenet_trained.pth\")\n",
    "print(\"\\nModel saved as googlenet_trained.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    0: \"Apple___Apple_scab\",\n",
    "    1: \"Apple___Black_rot\",\n",
    "    2: \"Apple___Cedar_apple_rust\",\n",
    "    3: \"Apple___healthy\",\n",
    "    4: \"Blueberry___healthy\",\n",
    "    5: \"Cherry_(including_sour)___Powdery_mildew\",\n",
    "    6: \"Cherry_(including_sour)___healthy\",\n",
    "    7: \"Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\",\n",
    "    8: \"Corn_(maize)___Common_rust_\",\n",
    "    9: \"Corn_(maize)___Northern_Leaf_Blight\",\n",
    "    10: \"Corn_(maize)___healthy\",\n",
    "    11: \"Grape___Black_rot\",\n",
    "    12: \"Grape___Esca_(Black_Measles)\",\n",
    "    13: \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
    "    14: \"Grape___healthy\",\n",
    "    15: \"Orange___Haunglongbing_(Citrus_greening)\",\n",
    "    16: \"Peach___Bacterial_spot\",\n",
    "    17: \"Peach___healthy\",\n",
    "    18: \"Pepper,_bell___Bacterial_spot\",\n",
    "    19: \"Pepper,_bell___healthy\",\n",
    "    20: \"Potato___Early_blight\",\n",
    "    21: \"Potato___Late_blight\",\n",
    "    22: \"Potato___healthy\",\n",
    "    23: \"Raspberry___healthy\",\n",
    "    24: \"Soybean___healthy\",\n",
    "    25: \"Squash___Powdery_mildew\",\n",
    "    26: \"Strawberry___Leaf_scorch\",\n",
    "    27: \"Strawberry___healthy\",\n",
    "    28: \"Tomato___Bacterial_spot\",\n",
    "    29: \"Tomato___Early_blight\",\n",
    "    30: \"Tomato___Late_blight\",\n",
    "    31: \"Tomato___Leaf_Mold\",\n",
    "    32: \"Tomato___Septoria_leaf_spot\",\n",
    "    33: \"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "    34: \"Tomato___Target_Spot\",\n",
    "    35: \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "    36: \"Tomato___Tomato_mosaic_virus\",\n",
    "    37: \"Tomato___healthy\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class_names = class_map\n",
    "num_classes = len(class_names)\n",
    "def calculate_per_class_accuracy(model, data_loaders, device, datasets=[ \"Validation\", \"Test\"]):\n",
    "    for dataset_type, data_loader in zip(datasets, data_loaders):\n",
    "        model.eval()\n",
    "        class_correct = np.zeros(num_classes)\n",
    "        class_total = np.zeros(num_classes)\n",
    "\n",
    "        print(f\"\\nCalculating Per-Class {dataset_type} Accuracy...\")\n",
    "        with torch.no_grad():\n",
    "            for steps , (images, labels) in tqdm(enumerate(data_loader), desc=f\"{dataset_type} Progress\", leave=True):\n",
    "                if steps == 2000:\n",
    "                  break\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i].item()\n",
    "                    class_correct[label] += (predicted[i] == label).item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        print(f\"\\nFinal Per-Class {dataset_type} Accuracy:\\n\")\n",
    "        for i in range(num_classes):\n",
    "            if class_total[i] > 0:\n",
    "                accuracy = 100 * class_correct[i] / class_total[i]\n",
    "                print(f\"{class_names[i]}: {dataset_type} Accuracy = {accuracy:.2f}%\")\n",
    "            else:\n",
    "                print(f\"{class_names[i]}: {dataset_type} Accuracy = No samples available\")\n",
    "\n",
    "data_loaders = [val_loader, test_loader]\n",
    "datasets = [ \"Validation\", \"Test\"]\n",
    "calculate_per_class_accuracy(model, data_loaders, device, datasets=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_true = []\n",
    "y_scores = []\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for steps, (images, labels) in enumerate(tqdm(test_loader, desc=\"Calculating Test Accuracy\", total=2000)):\n",
    "        if steps == 1000:\n",
    "            break\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for steps, (images, labels) in enumerate(tqdm(test_loader, desc=\"Calculating Precision-Recall Data\", total=2000)):\n",
    "        if steps == 1000:\n",
    "            break\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_scores.extend(probs.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_scores = np.array(y_scores)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(class_names)):\n",
    "    precision, recall, _ = precision_recall_curve(y_true == i, y_scores[:, i])\n",
    "    avg_precision = average_precision_score(y_true == i, y_scores[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_names[i]} (AP={avg_precision:.2f})\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve for Plant Disease Classification\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
